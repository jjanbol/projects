{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1 - Script extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mPython Code Data\u001b[m\u001b[m                 \u001b[34mpython\u001b[m\u001b[m\n",
      "\u001b[34mjtatman_python-code-dataset-500k\u001b[m\u001b[m python_dedupe_definitions_v2.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting the scripts from jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines in data/python/python_train_2.jsonl: 30000\n"
     ]
    }
   ],
   "source": [
    "file_path = \"data/python/python_train_2.jsonl\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    num_lines = sum(1 for _ in f)\n",
    "\n",
    "print(f\"Total lines in {file_path}: {num_lines}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_base_ = [\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"data/shibing624:source_code/0000.parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df.to_csv(\"output.txt\", sep=\"\\t\", index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.txt\", \"w\") as f:\n",
    "    for row in df.itertuples(index=False):\n",
    "        f.write(\" \".join(map(str, row)) + \"\\n\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df22 = pd.read_csv(\"data/c++/all_c_cpp_release2.0.csv\", on_bad_lines=\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>authentication_required</th>\n",
       "      <th>availability_impact</th>\n",
       "      <th>cve_id</th>\n",
       "      <th>cve_page</th>\n",
       "      <th>cwe_id</th>\n",
       "      <th>access_complexity</th>\n",
       "      <th>confidentiality_impact</th>\n",
       "      <th>integrity_impact</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>...</th>\n",
       "      <th>update_date</th>\n",
       "      <th>vulnerability_classification</th>\n",
       "      <th>ref_link</th>\n",
       "      <th>commit_id</th>\n",
       "      <th>commit_message</th>\n",
       "      <th>files_changed</th>\n",
       "      <th>lang</th>\n",
       "      <th>project</th>\n",
       "      <th>version_after_fix</th>\n",
       "      <th>version_before_fix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Not required</td>\n",
       "      <td>Partial</td>\n",
       "      <td>CVE-2009-1194</td>\n",
       "      <td>https://www.cvedetails.com/cve/CVE-2009-1194/</td>\n",
       "      <td>CWE-189</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Partial</td>\n",
       "      <td>Partial</td>\n",
       "      <td>2009-05-11</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>DoS Exec Code Overflow</td>\n",
       "      <td>https://github.com/bratsche/pango/commit/4de30...</td>\n",
       "      <td>4de30e5500eaeb49f4bf0b7a07f718e149a2ed5e</td>\n",
       "      <td>[glyphstring] Handle overflow with very long g...</td>\n",
       "      <td>{\"sha\": \"8fb70313eb8835dcce812a86209e2a7d88457...</td>\n",
       "      <td>C</td>\n",
       "      <td>pango</td>\n",
       "      <td>4de30e5500eaeb49f4bf0b7a07f718e149a2ed5e</td>\n",
       "      <td>1c9433bfe43890b102c8cead8ab3ee34b44c5c37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Not required</td>\n",
       "      <td>Partial</td>\n",
       "      <td>CVE-2010-2809</td>\n",
       "      <td>https://www.cvedetails.com/cve/CVE-2010-2809/</td>\n",
       "      <td>CWE-94</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Partial</td>\n",
       "      <td>Partial</td>\n",
       "      <td>2010-08-19</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>Exec Code</td>\n",
       "      <td>https://github.com/Dieterbe/uzbl/commit/9cc39c...</td>\n",
       "      <td>9cc39cb5c9396be013b5dc2ba7e4b3eaa647e975</td>\n",
       "      <td>Don't shell-interpret \\@SELECTED_URI (fixes FS...</td>\n",
       "      <td>{\"sha\": \"da2c583dc09acf7eb567df6c9c629e61f3c80...</td>\n",
       "      <td>C</td>\n",
       "      <td>uzbl</td>\n",
       "      <td>9cc39cb5c9396be013b5dc2ba7e4b3eaa647e975</td>\n",
       "      <td>afc0f873e873839da75a54e8ca8095d335527786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Not required</td>\n",
       "      <td>Partial</td>\n",
       "      <td>CVE-2010-2060</td>\n",
       "      <td>https://www.cvedetails.com/cve/CVE-2010-2060/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>Partial</td>\n",
       "      <td>Partial</td>\n",
       "      <td>2010-06-07</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>Exec Code</td>\n",
       "      <td>https://github.com/kr/beanstalkd/commit/2e8e8c...</td>\n",
       "      <td>2e8e8c6387ecdf5923dfc4d7718d18eba1b0873d</td>\n",
       "      <td>Discard job body bytes if the job is too big.\\...</td>\n",
       "      <td>{\"sha\": \"bcfb7d4b22c28d3f909d13dad54b4caa1284f...</td>\n",
       "      <td>C</td>\n",
       "      <td>beanstalkd</td>\n",
       "      <td>2e8e8c6387ecdf5923dfc4d7718d18eba1b0873d</td>\n",
       "      <td>62328a506b8ed24e52c264f073ecbf4e9254f861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Not required</td>\n",
       "      <td>Partial</td>\n",
       "      <td>CVE-2010-1155</td>\n",
       "      <td>https://www.cvedetails.com/cve/CVE-2010-1155/</td>\n",
       "      <td>CWE-20</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Partial</td>\n",
       "      <td>Partial</td>\n",
       "      <td>2010-04-16</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/ensc/irssi-proxy/commit/85b...</td>\n",
       "      <td>85bbc05b21678e80423815d2ef1dfe26208491ab</td>\n",
       "      <td>Check if an SSL certificate matches the hostna...</td>\n",
       "      <td>{\"sha\": \"5a9c9bc71553d37a17b89654bec0b6e98b567...</td>\n",
       "      <td>C</td>\n",
       "      <td>irssi-proxy</td>\n",
       "      <td>85bbc05b21678e80423815d2ef1dfe26208491ab</td>\n",
       "      <td>d5688da48306918cdfd79ee9b27abe377204befb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Not required</td>\n",
       "      <td>Partial</td>\n",
       "      <td>CVE-2010-1152</td>\n",
       "      <td>https://www.cvedetails.com/cve/CVE-2010-1152/</td>\n",
       "      <td>CWE-20</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-04-12</td>\n",
       "      <td>...</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>DoS</td>\n",
       "      <td>https://github.com/memcached/memcached/commit/...</td>\n",
       "      <td>d9cd01ede97f4145af9781d448c62a3318952719</td>\n",
       "      <td>Use strncmp when checking for large ascii mult...</td>\n",
       "      <td>{\"sha\": \"3e2e9c59e274910dd88af6fbb73006279b5a6...</td>\n",
       "      <td>C</td>\n",
       "      <td>memcached</td>\n",
       "      <td>d9cd01ede97f4145af9781d448c62a3318952719</td>\n",
       "      <td>ea0fec7989ba00cf68326d017fd801a1716f8855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>4427</td>\n",
       "      <td>Not required</td>\n",
       "      <td>Partial</td>\n",
       "      <td>CVE-2016-1691</td>\n",
       "      <td>https://www.cvedetails.com/cve/CVE-2016-1691/</td>\n",
       "      <td>CWE-119</td>\n",
       "      <td>High</td>\n",
       "      <td>Partial</td>\n",
       "      <td>Partial</td>\n",
       "      <td>2016-06-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>DoS Overflow</td>\n",
       "      <td>https://github.com/chromium/chromium/commit/e3...</td>\n",
       "      <td>e3aa8a56706c4abe208934d5c294f7b594b8b693</td>\n",
       "      <td>Enforce the WebUsbAllowDevicesForUrls policy\\n...</td>\n",
       "      <td>{\"sha\": \"ee879f588a9696691bde0e889dde076f2f525...</td>\n",
       "      <td>C</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>e3aa8a56706c4abe208934d5c294f7b594b8b693</td>\n",
       "      <td>fec152acbf487c58de34152b7f4e641b790d83c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4428</th>\n",
       "      <td>4428</td>\n",
       "      <td>Not required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CVE-2016-1692</td>\n",
       "      <td>https://www.cvedetails.com/cve/CVE-2016-1692/</td>\n",
       "      <td>CWE-284</td>\n",
       "      <td>Medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Partial</td>\n",
       "      <td>2016-06-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>Bypass</td>\n",
       "      <td>https://github.com/chromium/chromium/commit/0e...</td>\n",
       "      <td>0e7afef059c96e617c203c6199220d248e7bef49</td>\n",
       "      <td>Blacklist CoreAnimation renderer under VMWare\\...</td>\n",
       "      <td>{\"sha\": \"632fb8ec039c026eafd94877e5aaeb813c562...</td>\n",
       "      <td>C</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>0e7afef059c96e617c203c6199220d248e7bef49</td>\n",
       "      <td>8b3faf7c7be02e55d5ab94e8e9454859601fbd4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4429</th>\n",
       "      <td>4429</td>\n",
       "      <td>Not required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CVE-2016-1693</td>\n",
       "      <td>https://www.cvedetails.com/cve/CVE-2016-1693/</td>\n",
       "      <td>CWE-284</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Partial</td>\n",
       "      <td>2016-06-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/chromium/chromium/commit/60...</td>\n",
       "      <td>605b49c8d111940076b90123542d2ac54ed500e8</td>\n",
       "      <td>Pickers: Convert enums to IntDefs.\\n\\nBug: Non...</td>\n",
       "      <td>{\"sha\": \"30fee5875a4dc8bfaf89a1bc0fa33d5e1085c...</td>\n",
       "      <td>C</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>605b49c8d111940076b90123542d2ac54ed500e8</td>\n",
       "      <td>7e2e3d3b6aee725370fb34c4daa77d9d160fd9f3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4430</th>\n",
       "      <td>4430</td>\n",
       "      <td>Not required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CVE-2016-1694</td>\n",
       "      <td>https://www.cvedetails.com/cve/CVE-2016-1694/</td>\n",
       "      <td>CWE-284</td>\n",
       "      <td>Medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Partial</td>\n",
       "      <td>2016-06-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/chromium/chromium/commit/3a...</td>\n",
       "      <td>3af9c480c6f075c2aed3a818ae94dc5ea7c8db1e</td>\n",
       "      <td>Roll src/third_party/pdfium ea08d171755b..6906...</td>\n",
       "      <td>{\"sha\": \"2ade86f9f78679edce5d01d3a65802555962f...</td>\n",
       "      <td>C</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>3af9c480c6f075c2aed3a818ae94dc5ea7c8db1e</td>\n",
       "      <td>39dae8aa57c3d81ee552e37feab7fe60df71e382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431</th>\n",
       "      <td>4431</td>\n",
       "      <td>Not required</td>\n",
       "      <td>Partial</td>\n",
       "      <td>CVE-2016-1695</td>\n",
       "      <td>https://www.cvedetails.com/cve/CVE-2016-1695/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Partial</td>\n",
       "      <td>Partial</td>\n",
       "      <td>2016-06-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>DoS</td>\n",
       "      <td>https://github.com/chromium/chromium/commit/b6...</td>\n",
       "      <td>b65d200b9482194cb70fa3d534feace51644c45f</td>\n",
       "      <td>[Sheriff] Disable ChromeVoxLiveRegionsUnitTest...</td>\n",
       "      <td>{\"sha\": \"c7a6ad4b02c32fb6c9ed19f5d07541f160072...</td>\n",
       "      <td>C</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>b65d200b9482194cb70fa3d534feace51644c45f</td>\n",
       "      <td>48df1ecfab83689bc3a25ca248af8d2049e9f6e1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4432 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 authentication_required availability_impact         cve_id  \\\n",
       "0              0            Not required             Partial  CVE-2009-1194   \n",
       "1              1            Not required             Partial  CVE-2010-2809   \n",
       "2              2            Not required             Partial  CVE-2010-2060   \n",
       "3              3            Not required             Partial  CVE-2010-1155   \n",
       "4              4            Not required             Partial  CVE-2010-1152   \n",
       "...          ...                     ...                 ...            ...   \n",
       "4427        4427            Not required             Partial  CVE-2016-1691   \n",
       "4428        4428            Not required                 NaN  CVE-2016-1692   \n",
       "4429        4429            Not required                 NaN  CVE-2016-1693   \n",
       "4430        4430            Not required                 NaN  CVE-2016-1694   \n",
       "4431        4431            Not required             Partial  CVE-2016-1695   \n",
       "\n",
       "                                           cve_page   cwe_id  \\\n",
       "0     https://www.cvedetails.com/cve/CVE-2009-1194/  CWE-189   \n",
       "1     https://www.cvedetails.com/cve/CVE-2010-2809/   CWE-94   \n",
       "2     https://www.cvedetails.com/cve/CVE-2010-2060/      NaN   \n",
       "3     https://www.cvedetails.com/cve/CVE-2010-1155/   CWE-20   \n",
       "4     https://www.cvedetails.com/cve/CVE-2010-1152/   CWE-20   \n",
       "...                                             ...      ...   \n",
       "4427  https://www.cvedetails.com/cve/CVE-2016-1691/  CWE-119   \n",
       "4428  https://www.cvedetails.com/cve/CVE-2016-1692/  CWE-284   \n",
       "4429  https://www.cvedetails.com/cve/CVE-2016-1693/  CWE-284   \n",
       "4430  https://www.cvedetails.com/cve/CVE-2016-1694/  CWE-284   \n",
       "4431  https://www.cvedetails.com/cve/CVE-2016-1695/      NaN   \n",
       "\n",
       "     access_complexity confidentiality_impact integrity_impact publish_date  \\\n",
       "0               Medium                Partial          Partial   2009-05-11   \n",
       "1               Medium                Partial          Partial   2010-08-19   \n",
       "2                  Low                Partial          Partial   2010-06-07   \n",
       "3               Medium                Partial          Partial   2010-04-16   \n",
       "4                  Low                    NaN              NaN   2010-04-12   \n",
       "...                ...                    ...              ...          ...   \n",
       "4427              High                Partial          Partial   2016-06-05   \n",
       "4428            Medium                    NaN          Partial   2016-06-05   \n",
       "4429              High                    NaN          Partial   2016-06-05   \n",
       "4430            Medium                    NaN          Partial   2016-06-05   \n",
       "4431            Medium                Partial          Partial   2016-06-05   \n",
       "\n",
       "      ...  update_date vulnerability_classification  \\\n",
       "0     ...   2018-10-10      DoS Exec Code Overflow    \n",
       "1     ...   2017-08-16                   Exec Code    \n",
       "2     ...   2017-08-16                   Exec Code    \n",
       "3     ...   2017-08-16                          NaN   \n",
       "4     ...   2011-03-01                         DoS    \n",
       "...   ...          ...                          ...   \n",
       "4427  ...   2018-10-30                DoS Overflow    \n",
       "4428  ...   2018-10-30                      Bypass    \n",
       "4429  ...   2018-10-30                          NaN   \n",
       "4430  ...   2018-10-30                          NaN   \n",
       "4431  ...   2018-10-30                         DoS    \n",
       "\n",
       "                                               ref_link  \\\n",
       "0     https://github.com/bratsche/pango/commit/4de30...   \n",
       "1     https://github.com/Dieterbe/uzbl/commit/9cc39c...   \n",
       "2     https://github.com/kr/beanstalkd/commit/2e8e8c...   \n",
       "3     https://github.com/ensc/irssi-proxy/commit/85b...   \n",
       "4     https://github.com/memcached/memcached/commit/...   \n",
       "...                                                 ...   \n",
       "4427  https://github.com/chromium/chromium/commit/e3...   \n",
       "4428  https://github.com/chromium/chromium/commit/0e...   \n",
       "4429  https://github.com/chromium/chromium/commit/60...   \n",
       "4430  https://github.com/chromium/chromium/commit/3a...   \n",
       "4431  https://github.com/chromium/chromium/commit/b6...   \n",
       "\n",
       "                                     commit_id  \\\n",
       "0     4de30e5500eaeb49f4bf0b7a07f718e149a2ed5e   \n",
       "1     9cc39cb5c9396be013b5dc2ba7e4b3eaa647e975   \n",
       "2     2e8e8c6387ecdf5923dfc4d7718d18eba1b0873d   \n",
       "3     85bbc05b21678e80423815d2ef1dfe26208491ab   \n",
       "4     d9cd01ede97f4145af9781d448c62a3318952719   \n",
       "...                                        ...   \n",
       "4427  e3aa8a56706c4abe208934d5c294f7b594b8b693   \n",
       "4428  0e7afef059c96e617c203c6199220d248e7bef49   \n",
       "4429  605b49c8d111940076b90123542d2ac54ed500e8   \n",
       "4430  3af9c480c6f075c2aed3a818ae94dc5ea7c8db1e   \n",
       "4431  b65d200b9482194cb70fa3d534feace51644c45f   \n",
       "\n",
       "                                         commit_message  \\\n",
       "0     [glyphstring] Handle overflow with very long g...   \n",
       "1     Don't shell-interpret \\@SELECTED_URI (fixes FS...   \n",
       "2     Discard job body bytes if the job is too big.\\...   \n",
       "3     Check if an SSL certificate matches the hostna...   \n",
       "4     Use strncmp when checking for large ascii mult...   \n",
       "...                                                 ...   \n",
       "4427  Enforce the WebUsbAllowDevicesForUrls policy\\n...   \n",
       "4428  Blacklist CoreAnimation renderer under VMWare\\...   \n",
       "4429  Pickers: Convert enums to IntDefs.\\n\\nBug: Non...   \n",
       "4430  Roll src/third_party/pdfium ea08d171755b..6906...   \n",
       "4431  [Sheriff] Disable ChromeVoxLiveRegionsUnitTest...   \n",
       "\n",
       "                                          files_changed lang      project  \\\n",
       "0     {\"sha\": \"8fb70313eb8835dcce812a86209e2a7d88457...    C        pango   \n",
       "1     {\"sha\": \"da2c583dc09acf7eb567df6c9c629e61f3c80...    C         uzbl   \n",
       "2     {\"sha\": \"bcfb7d4b22c28d3f909d13dad54b4caa1284f...    C   beanstalkd   \n",
       "3     {\"sha\": \"5a9c9bc71553d37a17b89654bec0b6e98b567...    C  irssi-proxy   \n",
       "4     {\"sha\": \"3e2e9c59e274910dd88af6fbb73006279b5a6...    C    memcached   \n",
       "...                                                 ...  ...          ...   \n",
       "4427  {\"sha\": \"ee879f588a9696691bde0e889dde076f2f525...    C       Chrome   \n",
       "4428  {\"sha\": \"632fb8ec039c026eafd94877e5aaeb813c562...    C       Chrome   \n",
       "4429  {\"sha\": \"30fee5875a4dc8bfaf89a1bc0fa33d5e1085c...    C       Chrome   \n",
       "4430  {\"sha\": \"2ade86f9f78679edce5d01d3a65802555962f...    C       Chrome   \n",
       "4431  {\"sha\": \"c7a6ad4b02c32fb6c9ed19f5d07541f160072...    C       Chrome   \n",
       "\n",
       "                             version_after_fix  \\\n",
       "0     4de30e5500eaeb49f4bf0b7a07f718e149a2ed5e   \n",
       "1     9cc39cb5c9396be013b5dc2ba7e4b3eaa647e975   \n",
       "2     2e8e8c6387ecdf5923dfc4d7718d18eba1b0873d   \n",
       "3     85bbc05b21678e80423815d2ef1dfe26208491ab   \n",
       "4     d9cd01ede97f4145af9781d448c62a3318952719   \n",
       "...                                        ...   \n",
       "4427  e3aa8a56706c4abe208934d5c294f7b594b8b693   \n",
       "4428  0e7afef059c96e617c203c6199220d248e7bef49   \n",
       "4429  605b49c8d111940076b90123542d2ac54ed500e8   \n",
       "4430  3af9c480c6f075c2aed3a818ae94dc5ea7c8db1e   \n",
       "4431  b65d200b9482194cb70fa3d534feace51644c45f   \n",
       "\n",
       "                            version_before_fix  \n",
       "0     1c9433bfe43890b102c8cead8ab3ee34b44c5c37  \n",
       "1     afc0f873e873839da75a54e8ca8095d335527786  \n",
       "2     62328a506b8ed24e52c264f073ecbf4e9254f861  \n",
       "3     d5688da48306918cdfd79ee9b27abe377204befb  \n",
       "4     ea0fec7989ba00cf68326d017fd801a1716f8855  \n",
       "...                                        ...  \n",
       "4427  fec152acbf487c58de34152b7f4e641b790d83c8  \n",
       "4428  8b3faf7c7be02e55d5ab94e8e9454859601fbd4f  \n",
       "4429  7e2e3d3b6aee725370fb34c4daa77d9d160fd9f3  \n",
       "4430  39dae8aa57c3d81ee552e37feab7fe60df71e382  \n",
       "4431  48df1ecfab83689bc3a25ca248af8d2049e9f6e1  \n",
       "\n",
       "[4432 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting the scripts from h and cpp and c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "cpp_files = glob.glob(\"data/c/c_master/*.c\", recursive=True)\n",
    "#h_files = glob.glob(\"/data/c++/cpp_tutorial_samples/*.h\", recursive=True)\n",
    "\n",
    "all_files = cpp_files\n",
    "\n",
    "\n",
    "with open(\"combined_output.txt\", \"w\") as outfile:\n",
    "    for file in all_files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as infile:\n",
    "            outfile.write(f\"// Contents of {file}\\n\\n\") \n",
    "            outfile.write(infile.read())\n",
    "            outfile.write(\"\\n\\n\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrays and Pointers 1.cpp         arrays.cpp\n",
      "Arrays and Pointers 2.cpp         character arrays.cpp\n",
      "Arrays of Pointers copy.cpp       cond operatir.cpp\n",
      "Basics.cpp                        const Qualifier and Pointers.cpp\n",
      "Call By Reference.cpp             creating.cpp\n",
      "Declaring a Function.cpp          do while Structure.cpp\n",
      "Function Default Argument.cpp     efficient.cpp\n",
      "Function Template.cpp             enumeration.cpp\n",
      "Histogram.cpp                     fiunc potintes.cpp\n",
      "If else Structure.cpp             for Structure.cpp\n",
      "Incrementing and Decrementing.cpp getline Function.cpp\n",
      "Inline Functions.cpp              graphicsl.cpp\n",
      "Makefile                          init.cpp\n",
      "Math Library Functions.cpp        iterative.cpp\n",
      "Maximum.cpp                       new and delete.cpp\n",
      "Overloaded Functions.cpp          passing to function.cpp\n",
      "PhoneNum.cpp                      recurs.cpp\n",
      "PhoneNum.h                        setw.cpp\n",
      "Pointers.cpp                      simple.cpp\n",
      "Prog copy.cpp                     sizeof Operator.cpp\n",
      "Prog.cpp                          source.txt\n",
      "ReadMe.md                         static arrays.cpp\n",
      "Recursive Function Calls.cpp      strcat and strncat.cpp\n",
      "Scoping.cpp                       strcmp and strncmp.cpp\n",
      "Structures.cpp                    strcpy and strncpy.cpp\n",
      "Type Definition.cpp               strlen.cpp\n",
      "array in functions.cpp            strtok Function.cpp\n",
      "array of pointers to func.cpp     switch Structure.cpp\n",
      "arrays and pointers.cpp           void Pointers.cpp\n",
      "arrays of pointers.cpp\n"
     ]
    }
   ],
   "source": [
    "!ls data/c++/cpp_tutorial_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpp_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting scripts from parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/c++/shibing624:source_code/0000.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/c++/shibing624:source_code/0000.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m txt_data \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mto_string(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llm_14825/lib/python3.10/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llm_14825/lib/python3.10/site-packages/pandas/io/parquet.py:267\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    265\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    275\u001b[0m         path_or_handle,\n\u001b[1;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    280\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llm_14825/lib/python3.10/site-packages/pandas/io/parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llm_14825/lib/python3.10/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/c++/shibing624:source_code/0000.parquet'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_parquet(\"data/c++/shibing624:source_code/0000.parquet\")\n",
    "\n",
    "txt_data = df.to_string(index=False) \n",
    "\n",
    "\n",
    "with open(\"output.txt\", \"w\") as f:\n",
    "    f.write(txt_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting the scripts from jsonl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 JSONL files.\n",
      "Conversion completed.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "\n",
    "jsonl_files = glob.glob(\"data/python/python_codesearch_net(with meta)/*.jsonl\", recursive=True)\n",
    "\n",
    "print(f\"Found {len(jsonl_files)} JSONL files.\") \n",
    "\n",
    "with open(\"combined_output.txt\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for file in jsonl_files:\n",
    "        try:\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as infile:\n",
    "                outfile.write(f\"// Contents of {file}\\n\\n\")  \n",
    "                for line in infile:\n",
    "                    try:\n",
    "                        json_obj = json.loads(line)  \n",
    "                        \n",
    "\n",
    "                        repo = json_obj.get(\"repo\", \"N/A\")\n",
    "                        path = json_obj.get(\"path\", \"N/A\")\n",
    "                        func_name = json_obj.get(\"func_name\", \"N/A\")\n",
    "                        language = json_obj.get(\"language\", \"N/A\")\n",
    "                        code = json_obj.get(\"code\", \"N/A\")\n",
    "                        docstring = json_obj.get(\"docstring\", \"N/A\")\n",
    "                        url = json_obj.get(\"url\", \"N/A\")\n",
    "\n",
    "\n",
    "                        outfile.write(f\"Repository: {repo}\\n\")\n",
    "                        outfile.write(f\"File Path: {path}\\n\")\n",
    "                        outfile.write(f\"Function: {func_name}\\n\")\n",
    "                        outfile.write(f\"Language: {language}\\n\")\n",
    "                        outfile.write(f\"URL: {url}\\n\\n\")\n",
    "                        outfile.write(\"Docstring:\\n\")\n",
    "                        outfile.write(f\"{docstring}\\n\\n\")\n",
    "                        outfile.write(\"Code:\\n\")\n",
    "                        outfile.write(f\"{code}\\n\\n\")\n",
    "                        outfile.write(\"=\"*80 + \"\\n\\n\")  \n",
    "\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Skipping invalid JSON in {file}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "print(\"Conversion completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting script from matlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79 MATLAB files.\n",
      "Conversion completed.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "matlab_files = glob.glob(\"data/matlab/matlab-master2/**/*.m\", recursive=True)\n",
    "\n",
    "print(f\"Found {len(matlab_files)} MATLAB files.\")  \n",
    "\n",
    "with open(\"combined_output.txt\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for file in matlab_files:\n",
    "        try:\n",
    "            with open(file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as infile:\n",
    "                outfile.write(f\"// Contents of {file}\\n\\n\")  \n",
    "                \n",
    "\n",
    "                outfile.write(infile.read())\n",
    "                outfile.write(\"\\n\\n\" + \"=\"*80 + \"\\n\\n\")  \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "print(\"Conversion completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting script from python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31 Python files.\n",
      "Conversion completed.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "python_files = glob.glob(\"data/python/algo_master2/*.py\", recursive=True)\n",
    "\n",
    "print(f\"Found {len(python_files)} Python files.\")  \n",
    "\n",
    "with open(\"combined_output.txt\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for file in python_files:\n",
    "        try:\n",
    "            with open(file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as infile:\n",
    "                outfile.write(f\"# Contents of {file}\\n\\n\")  \n",
    "                \n",
    "                outfile.write(infile.read())\n",
    "                outfile.write(\"\\n\\n\" + \"=\"*80 + \"\\n\\n\") \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "print(\"Conversion completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting script from jave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 Java files.\n",
      "Java files successfully combined into 'combined_java_output.txt'.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Find all Java files recursively in the specified directory\n",
    "java_files = glob.glob(\"data/java/sorting/*.java\", recursive=True)\n",
    "\n",
    "print(f\"Found {len(java_files)} Java files.\")  \n",
    "\n",
    "# Write all Java files into a single text file\n",
    "with open(\"combined_output.txt\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for file in java_files:\n",
    "        try:\n",
    "            with open(file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as infile:\n",
    "                outfile.write(f\"// Contents of {file}\\n\\n\")  \n",
    "                outfile.write(infile.read())\n",
    "                outfile.write(\"\\n\\n\" + \"=\"*80 + \"\\n\\n\")  \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "print(\"Java files successfully combined into 'combined_java_output.txt'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combining all the txt into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 337 text files.\n",
      "Merging completed. Output saved as 'merged_output.txt'.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "txt_files = glob.glob(\"data/python/python_official_documentation/*.txt\", recursive=True)\n",
    "\n",
    "print(f\"Found {len(txt_files)} text files.\") \n",
    "\n",
    "with open(\"merged_output.txt\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for file in txt_files:\n",
    "        try:\n",
    "            with open(file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as infile:\n",
    "                outfile.write(f\"// Contents of {file}\\n\\n\") \n",
    "                \n",
    "                outfile.write(infile.read())\n",
    "                outfile.write(\"\\n\\n\" + \"=\"*80 + \"\\n\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "print(\"Merging completed. Output saved as 'merged_output.txt'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2 - RAG Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building rag pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'python', 'java', 'cpp', 'matlab', 'c']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = \"data\"\n",
    "os.listdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/c/c_2/combined_output.txt',\n",
       " 'data/c/c_2/source.txt',\n",
       " 'data/c/C programs/combined_output.txt',\n",
       " 'data/c/C programs/source.txt',\n",
       " 'data/c/c_master/combined_output.txt',\n",
       " 'data/c/c_master/source.txt',\n",
       " 'data/c/Intro-to-C-master/combined_output.txt',\n",
       " 'data/c/Intro-to-C-master/source.txt']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpp_files = glob.glob(\"data/c/**/**.txt\", recursive=True)\n",
    "cpp_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing language folder: python\n",
      "  Processing source: python_algo\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'python', 'author': 'Christian Clauss', 'source': 'https://github.com/TheAlgorithms/Python'}\n",
      "    Found file: source.txt\n",
      "  Processing source: algo_master2\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'python', 'author': 'Keon', 'source': 'https://github.com/keon/algorithms'}\n",
      "    Found file: source.txt\n",
      "  Processing source: learn-python-master\n",
      "    Found file: .flake8\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'python', 'author': 'Oleksii Trekhleb', 'source': 'https://github.com/trekhleb/learn-python'}\n",
      "    Found file: source.txt\n",
      "    Found file: .gitignore\n",
      "    Found file: .github\n",
      "    Found file: .travis.yml\n",
      "    Found file: separate\n",
      "  Processing source: Python Code Data\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'python', 'author': 'veeralakrishna', 'source': 'https://www.kaggle.com/datasets/veeralakrishna/python-code-data'}\n",
      "    Found file: source.txt\n",
      "    Found file: python-code-data-metadata.json\n",
      "  Processing source: natural language to python code\n",
      "    Found file: coding-problems-and-solution-python-code-metadata.json\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'python', 'author': 'JANDRIK LANA', 'source': 'https://www.kaggle.com/datasets/linkanjarad/coding-problems-and-solution-python-code'}\n",
      "    Found file: source.txt\n",
      "  Processing source: fopnp-m\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'python', 'author': 'Brandon Rhodes', 'source': 'https://github.com/brandon-rhodes/fopnp'}\n",
      "    Found file: source.txt\n",
      "    Found file: .gitignore\n",
      "    Found file: separate\n",
      "Processing language folder: java\n",
      "  Processing source: dsa_series\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'java', 'author': 'RaviPaghadiyal', 'source': 'https://github.com/Ravi-Paghadiyal/DSA-Series-'}\n",
      "    Found file: source.txt\n",
      "  Processing source: algo-master\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'java', 'author': 'Pedro GÃ³mez', 'source': 'https://github.com/pedrovgs/Algorithms'}\n",
      "    Found file: source.txt\n",
      "  Processing source: sorting\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'java', 'author': 'Steven Sams', 'source': 'https://github.com/stevensams/SortingAlgorithms/tree/master/src/main/java/sams/steven/algorithms'}\n",
      "    Found file: source.txt\n",
      "  Processing source: java_coding_samples\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'java', 'author': 'Institute of Professional Studies', 'source': 'https://ipsgwalior.org/download/javaprograms.pdf'}\n",
      "    Found file: source.txt\n",
      "  Processing source: java-master\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'java', 'author': 'Hardik Pawar', 'source': 'https://github.com/TheAlgorithms/Java'}\n",
      "    Found file: source.txt\n",
      "Processing language folder: cpp\n",
      "  Processing source: non_brownian_trait_evol\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'cpp', 'author': 'Public Library of Science', 'source': 'https://plos.figshare.com/articles/dataset/Detecting_Non_Brownian_Trait_Evolution_in_Adaptive_Radiations/152767?file=470486'}\n",
      "    Found file: source.txt\n",
      "    Found file: ReadMe.txt\n",
      "  Processing source: cpp_tutorial_samples\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'cpp', 'author': 'Sina Iravanian', 'source': 'https://github.com/sinairv/Cpp-Tutorial-Samples'}\n",
      "    Found file: source.txt\n",
      "    Found file: .gitignore\n",
      "    Found file: .github\n",
      "    Found file: separate\n",
      "  Processing source: cpp_examples\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'cpp', 'author': 'geeksforgeeks', 'source': 'https://www.geeksforgeeks.org/cpp-programming-examples/'}\n",
      "    Found file: source.txt\n",
      "Processing language folder: matlab\n",
      "  Processing source: matlab-midi-master\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'matlab', 'author': 'Ken Schutte', 'source': 'source URL: https://github.com/kts/matlab-midi'}\n",
      "    Found file: eparate\n",
      "    Found file: source.txt\n",
      "  Processing source: matlab-master2\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'matlab', 'author': 'Christopher Duncombe Rae', 'source': 'https://github.com/duncombe/matlab'}\n",
      "    Found file: source.txt\n",
      "    Found file: .gitignore\n",
      "    Found file: separate\n",
      "  Processing source: cheat_sheet\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'matlab', 'author': 'krishnr', 'source': 'https://github.com/krishnr/MATLAB-cheat-sheet'}\n",
      "    Found file: source.txt\n",
      "  Processing source: MATLAB-master\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'matlab', 'author': 'Robert W. Ellenberg', 'source': 'https://github.com/robEllenberg/MATLAB'}\n",
      "    Found file: .gitmodules\n",
      "    Found file: source.txt\n",
      "    Found file: .gitignore\n",
      "    Found file: separate\n",
      "  Processing source: lecture_files-master\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'matlab', 'author': 'Tobias Kuhn', 'source': 'https://github.com/msssm/lecture_files'}\n",
      "    Found file: source.txt\n",
      "    Found file: .gitignore\n",
      "    Found file: separate\n",
      "  Processing source: matlab_book\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'matlab', 'author': 'Christos Xenophontos', 'source': 'https://math.loyola.edu/~loberbro/matlab/Beginners_guide_to_MATLAB.pdf'}\n",
      "    Found file: source.txt\n",
      "  Processing source: matlab-master1\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'matlab', 'author': 'Jaakko Luttinen', 'source': 'https://github.com/jluttine/matlab'}\n",
      "    Found file: source.txt\n",
      "    Found file: .gitignore\n",
      "    Found file: separate\n",
      "  Processing source: matlab-tools-master\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'matlab', 'author': 'Katrin Honauer & Ole Johannsen', 'source': 'https://github.com/lightfield-analysis/matlab-tools'}\n",
      "    Found file: source.txt\n",
      "    Found file: separate\n",
      "Processing language folder: c\n",
      "  Processing source: c_2\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'c', 'author': 'mnpaunov', 'source': 'https://github.com/ProgrammingSimpleSteps/c-examples'}\n",
      "    Found file: source.txt\n",
      "    Found file: separate\n",
      "  Processing source: C programs\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'c', 'author': 'ADARSH BIRADAR', 'source': 'https://www.kaggle.com/datasets/adarshbiradar/c-programs/data'}\n",
      "    Found file: c-programs-metadata.json\n",
      "    Found file: source.txt\n",
      "  Processing source: c_master\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'c', 'author': 'Abraham', 'source': 'https://github.com/AllAlgorithms/c'}\n",
      "    Found file: source.txt\n",
      "  Processing source: Intro-to-C-master\n",
      "    Found file: combined_output.txt\n",
      "      Content of combined_output.txt loaded.\n",
      "{'language': 'c', 'author': 'Patrick Wheeler', 'source': 'https://github.com/txrxlabs/Intro-to-C'}\n",
      "    Found file: source.txt\n",
      "    Found file: separate\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document \n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./key.json\"\n",
    "root = \"data\" \n",
    "langs  = ['c', 'cpp', 'go', 'java', 'javascript', 'matlab', 'python']\n",
    "embedding_model = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"code_langs\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=\"./chromaDB_v2\"\n",
    ")\n",
    "\n",
    "for lang_folder in os.listdir(root):\n",
    "    if lang_folder in langs:\n",
    "        print(f\"Processing language folder: {lang_folder}\")  \n",
    "        lang_folder_path = os.path.join(root, lang_folder)  \n",
    "\n",
    "        for source in os.listdir(lang_folder_path):\n",
    "            if source != \".DS_Store\":  \n",
    "                source_path = os.path.join(lang_folder_path, source)  \n",
    "                print(f\"  Processing source: {source}\")  \n",
    "\n",
    "                if os.path.isdir(source_path):\n",
    "                    for file in os.listdir(source_path):\n",
    "                        if file != \".DS_Store\":  \n",
    "                            print(f\"    Found file: {file}\")  \n",
    "                            file_path = os.path.join(source_path, file)  \n",
    "\n",
    "                            if file == \"combined_output.txt\":\n",
    "                                with open(file_path, 'r') as f:\n",
    "                                    content = f.read()\n",
    "                                    print(f\"      Content of {file} loaded.\")\n",
    "\n",
    "                                    splitter = RecursiveCharacterTextSplitter(\n",
    "                                        chunk_size=1000,\n",
    "                                        chunk_overlap=100,\n",
    "                                    )\n",
    "                                    splitted_snippet = splitter.split_text(content)\n",
    "\n",
    "                                with open(f\"{root}/{lang_folder}/{source}/source.txt\") as meta:\n",
    "                                    content = meta.read()\n",
    "                                    meta_data = content.split(',')\n",
    "                                    meta_data = {\n",
    "                                        \"language\": lang_folder,\n",
    "                                        \"author\": meta_data[1].strip(),\n",
    "                                        \"source\": meta_data[0].strip()\n",
    "                                    }\n",
    "                                    print(meta_data)\n",
    "\n",
    "\n",
    "                                documents = [Document(page_content=chunk, metadata=meta_data) for chunk in splitted_snippet]\n",
    "\n",
    "\n",
    "                                vector_store.add_documents(documents=documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      "// Contents of data/c++/cpp_tutorial_samples/If else Structure.cpp\n",
      "\n",
      "// In an if statement it is not necessary for the expression to be a boolean one.\n",
      "// If a value such as an integer is given to it, it checks if the value is zero or not.\n",
      "// If it is zero it plays the roll FALSE.\n",
      "// If it is not zero (even if it is negative) it plays the roll of TRUE.\n",
      "// As an example refer to line : 27.\n",
      "#include <iostream>\n",
      "using namespace std;\n",
      "\n",
      "int main ()\n",
      "{\n",
      "\tint grade;\n",
      "\t\n",
      "\tcout << \"Enter your grade : \";\n",
      "\tcin >> grade;\n",
      "\tif (grade >= 90)\n",
      "\t\tcout << \"A\\n\";\n",
      "\telse if (grade >= 80)\n",
      "\t\tcout << \"B\\n\";\n",
      "\telse if (grade >= 70)\n",
      "\t\tcout << \"C\\n\";\n",
      "\telse if (grade >= 60)\n",
      "\t\tcout << \"D\\n\";\n",
      "\telse\n",
      "\t{\n",
      "\t\tcout << \"F : Fail.\\n\";\n",
      "\t\tcout << \"You must take this course again.\\n\";\n",
      "\t}\n",
      "\tif(grade)\n",
      "\t\tcout << \"Your grade wasn't zero.\" << endl;\n",
      "\telse\n",
      "\t\tcout << \"Your grade was zero.\" << endl;\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "\n",
      "// Contents of data/c++/cpp_tutorial_samples/iterative.cpp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "\n",
    "query = \" what is if statement in java\"\n",
    "results = vector_store.similarity_search(query, k=1)  \n",
    "\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Result {i+1}:\\n{result.page_content}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      "// Contents of data/c++/cpp_tutorial_samples/If else Structure.cpp\n",
      "\n",
      "// In an if statement it is not necessary for the expression to be a boolean one.\n",
      "// If a value such as an integer is given to it, it checks if the value is zero or not.\n",
      "// If it is zero it plays the roll FALSE.\n",
      "// If it is not zero (even if it is negative) it plays the roll of TRUE.\n",
      "// As an example refer to line : 27.\n",
      "#include <iostream>\n",
      "using namespace std;\n",
      "\n",
      "int main ()\n",
      "{\n",
      "\tint grade;\n",
      "\t\n",
      "\tcout << \"Enter your grade : \";\n",
      "\tcin >> grade;\n",
      "\tif (grade >= 90)\n",
      "\t\tcout << \"A\\n\";\n",
      "\telse if (grade >= 80)\n",
      "\t\tcout << \"B\\n\";\n",
      "\telse if (grade >= 70)\n",
      "\t\tcout << \"C\\n\";\n",
      "\telse if (grade >= 60)\n",
      "\t\tcout << \"D\\n\";\n",
      "\telse\n",
      "\t{\n",
      "\t\tcout << \"F : Fail.\\n\";\n",
      "\t\tcout << \"You must take this course again.\\n\";\n",
      "\t}\n",
      "\tif(grade)\n",
      "\t\tcout << \"Your grade wasn't zero.\" << endl;\n",
      "\telse\n",
      "\t\tcout << \"Your grade was zero.\" << endl;\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "\n",
      "// Contents of data/c++/cpp_tutorial_samples/iterative.cpp\n",
      "\n",
      "Metadata:\n",
      "  author: Sina Iravanian\n",
      "  language: cpp\n",
      "  source: https://github.com/sinairv/Cpp-Tutorial-Samples\n",
      "\n",
      "Result 2:\n",
      "// Contents of data/c++/cpp_tutorial_samples/cond operatir.cpp\n",
      "\n",
      "// Introducing the conditional operator ?: which takes 3 operands.\n",
      "// Structure:  A ? B : C\n",
      "// Conditional Operator together with the operands form the conditional expression.\n",
      "// 'A' represents a condition which is True or False.\n",
      "// If 'A' is True then 'B' is replaced by the entire conditonal expression.\n",
      "// If 'A' is False then 'C' is replaced by the entire conditional expression.\n",
      "// So the conditional operator does not return values, but replaces operands with the whole expression.\n",
      "\n",
      "#include <iostream>\n",
      "using namespace std;\n",
      "\n",
      "int main()\n",
      "{\n",
      "\tint grade;\n",
      "\tcout << \"Enter the grade : \";\n",
      "\tcin >> grade;\n",
      "\tcout << (grade >= 60 ? \"Passed\\n\" : \"Failed\\n\");\n",
      "\tgrade >=60 ? cout << \"Passed\\n\" : cout << \"Failed\\n\";\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "\n",
      "// Contents of data/c++/cpp_tutorial_samples/graphicsl.cpp\n",
      "\n",
      "#include <iostream>\n",
      "#include <iomanip>\n",
      "using namespace std;\n",
      "\n",
      "Metadata:\n",
      "  author: Sina Iravanian\n",
      "  language: cpp\n",
      "  source: https://github.com/sinairv/Cpp-Tutorial-Samples\n",
      "\n",
      "Result 3:\n",
      "// Contents of data/c/Intro-to-C-master/0008-if-statement.c\n",
      "\n",
      "#include <stdio.h>\n",
      "\n",
      "/* related: ../exercises/0008-fizz-buzz.txt */\n",
      "\n",
      "int main()\n",
      "{\n",
      "\n",
      "\tint i;\n",
      "\n",
      "\tfor (i = 0; i < 100; i++) {\n",
      "\n",
      "\t\t/* Examples of if statements.... */\n",
      "\t\tprintf(\"i = %d\", i);\n",
      "\t\tif ((i % 2) == 0)\n",
      "\t\t\tprintf(\" which is even\");\n",
      "\t\telse\n",
      "\t\t\tprintf(\" which is odd\");\n",
      "\t\tif ((i % 3) == 0)\n",
      "\t\t\tprintf(\" and divisible by 3\");\n",
      "\t\tprintf(\".\\n\");\n",
      "\n",
      "Metadata:\n",
      "  author: Patrick Wheeler\n",
      "  language: c\n",
      "  source: https://github.com/txrxlabs/Intro-to-C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"what is if statement in cpp\"\n",
    "results = vector_store.similarity_search(query, k=3)  \n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Result {i + 1}:\\n{result.page_content}\\n\")\n",
    "    print(\"Metadata:\")\n",
    "    for key, value in result.metadata.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing the rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janbol/Downloads/GitHub/course-project-option-2-liangchenhong/rag.py:12: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store = Chroma(\n"
     ]
    }
   ],
   "source": [
    "from rag import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'author': 'Oleksii Trekhleb', 'language': 'python', 'source': 'https://github.com/trekhleb/learn-python'}, page_content='\"\"\"FOR statement\\n\\n@see: https://docs.python.org/3/tutorial/controlflow.html\\n\\nThe for statement in Python differs a bit from what you may be used to in C or Pascal.\\nRather than always iterating over an arithmetic progression of numbers (like in Pascal), or\\ngiving the user the ability to define both the iteration step and halting condition (as C),\\nPythonâ€™s for statement iterates over the items of any sequence (a list or a string), in the\\norder that they appear in the sequence. For example (no pun intended):\\n\"\"\"\\n\\n\\n# pylint: disable=too-many-locals\\ndef test_for_statement():\\n    \"\"\"FOR statement\"\"\"\\n\\n    # Measure some strings:\\n    words = [\\'cat\\', \\'window\\', \\'defenestrate\\']\\n    words_length = 0\\n\\n    for word in words:\\n        words_length += len(word)\\n\\n    # \"cat\" length is 3\\n    # \"window\" length is 6\\n    # \"defenestrate\" length is 12\\n    assert words_length == (3 + 6 + 12)')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, meta1, meta2 = retrieval_augmented_generation(\"what is the for loop in python?\")\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['author', 'language', 'source']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oleksii Trekhleb', 'python', 'https://github.com/trekhleb/learn-python']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"\"\"FOR statement',\n",
       " '',\n",
       " '@see: https://docs.python.org/3/tutorial/controlflow.html',\n",
       " '',\n",
       " 'The for statement in Python differs a bit from what you may be used to in C or Pascal.',\n",
       " 'Rather than always iterating over an arithmetic progression of numbers (like in Pascal), or',\n",
       " 'giving the user the ability to define both the iteration step and halting condition (as C),',\n",
       " 'Pythonâ€™s for statement iterates over the items of any sequence (a list or a string), in the',\n",
       " 'order that they appear in the sequence. For example (no pun intended):',\n",
       " '\"\"\"',\n",
       " '',\n",
       " '',\n",
       " '# pylint: disable=too-many-locals',\n",
       " 'def test_for_statement():',\n",
       " '    \"\"\"FOR statement\"\"\"',\n",
       " '',\n",
       " '    # Measure some strings:',\n",
       " \"    words = ['cat', 'window', 'defenestrate']\",\n",
       " '    words_length = 0',\n",
       " '',\n",
       " '    for word in words:',\n",
       " '        words_length += len(word)',\n",
       " '',\n",
       " '    # \"cat\" length is 3',\n",
       " '    # \"window\" length is 6',\n",
       " '    # \"defenestrate\" length is 12',\n",
       " '    assert words_length == (3 + 6 + 12)']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].page_content.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"FOR statement\n",
      "\n",
      "@see: https://docs.python.org/3/tutorial/controlflow.html\n",
      "\n",
      "The for statement in Python differs a bit from what you may be used to in C or Pascal.\n",
      "Rather than always iterating over an arithmetic progression of numbers (like in Pascal), or\n",
      "giving the user the ability to define both the iteration step and halting condition (as C),\n",
      "Pythonâ€™s for statement iterates over the items of any sequence (a list or a string), in the\n",
      "order that they appear in the sequence. For example (no pun intended):\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# pylint: disable=too-many-locals\n",
      "def test_for_statement():\n",
      "    \"\"\"FOR statement\"\"\"\n",
      "\n",
      "    # Measure some strings:\n",
      "    words = ['cat', 'window', 'defenestrate']\n",
      "    words_length = 0\n",
      "\n",
      "    for word in words:\n",
      "        words_length += len(word)\n",
      "\n",
      "    # \"cat\" length is 3\n",
      "    # \"window\" length is 6\n",
      "    # \"defenestrate\" length is 12\n",
      "    assert words_length == (3 + 6 + 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lines = output[0].page_content.split(\"\\n\")\n",
    "\n",
    "\n",
    "joined_string = \"\\n\".join(lines)\n",
    "\n",
    "print(joined_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "import vertexai\n",
    "import wikipedia  # Wikipedia library\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from rag import *\n",
    "import wikipediaapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./key.json\"\n",
    "\n",
    "PROJECT_ID = \"nih-cl-cm500-chenhonl-3a5d\"  # Replace with your actual project ID\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "# Initialize the LLM model\n",
    "llm = VertexAI(\n",
    "    model_name=\"gemini-1.5-pro-001\",\n",
    "    max_output_tokens=512,\n",
    "    temperature=0.5,\n",
    "    top_p=0.9,\n",
    "    top_k=40,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History of Python\n",
      "Please read more here on related articles : https://en.wikipedia.org/wiki/History_of_Python\n",
      "List of Python software\n",
      "Please read more here on related articles : https://en.wikipedia.org/wiki/List_of_Python_software\n",
      "Python syntax and semantics\n",
      "Please read more here on related articles : https://en.wikipedia.org/wiki/Python_syntax_and_semantics\n"
     ]
    }
   ],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia(user_agent=\"project\")\n",
    "page = wiki_wiki.page(\"python\"+\" programming\")\n",
    "wiki_links = list(page.links.keys())\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "            input_variables=[\"language\", \"wikipedia_links\"],\n",
    "            template=(\n",
    "            '''You are a helpful and professional AI assistant that looks at {wikipedia_links} and \n",
    "            chooses the most related 4 wikipedia titles to the programming {language}. \n",
    "            You will present these three titles as python string like so: title1, title2, title3, title4.\n",
    "            Do not provide anything else.'''\n",
    "            )\n",
    "        )    \n",
    "    \n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "result = chain.invoke({\"language\": \"python\", \"wikipedia_links\": wiki_links})\n",
    "\n",
    "\n",
    "'''a = result[\"text\"].split(\",\")\n",
    "first = a[0]\n",
    "clean = first[1:-1]\n",
    "print(clean)\n",
    "\n",
    "page = wiki_wiki.page(clean)\n",
    "page.fullurl'''\n",
    "\n",
    "\n",
    "splitted = result[\"text\"].split(\",\")\n",
    "for idx in range(1, len(splitted)):\n",
    "        ignore_first = splitted[idx]\n",
    "        clean = ignore_first[2:-1]\n",
    "        print(clean)\n",
    "        page = wiki_wiki.page(clean)\n",
    "\n",
    "        print(f\"Please read more here on related articles : {page.fullurl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_14825",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
